# ============================================================================
# PDF to Audio Converter - Default Configuration
# ============================================================================
# This is the default configuration file for the PDF to Audio converter.
# Copy this file to 'config.yml' and modify the settings as needed.

# ============================================================================
# TEXT-TO-SPEECH (TTS) CONFIGURATION
# ============================================================================
tts:
  # TTS Provider: Choose your text-to-speech engine
  # Options: "gtts" (free), "openai" (premium), "aws" (premium)
  provider: "gtts"

  # Speaking rate/speed control (range: 0.25 - 2.0)
  # 1.0 = normal speed, 2.0 = twice as fast, 0.5 = half speed
  speaking_rate: 1.0

  # Default language for TTS (can be overridden with --lang parameter)
  default_language: "en"

  # Legacy setting for Google TTS slow speech (rarely needed)
  slow: false

  # Language code mappings for special cases
  # Maps non-standard codes to standard ones
  language_mappings:
    es_la: "es"    # Spanish Latin America -> Spanish
    es-MX: "es"    # Spanish Mexico -> Spanish (gTTS)
    en_us: "en"    # English US -> English
    en_uk: "en"    # English UK -> English

  # Voice configuration for each TTS provider
  voice:
    # Google TTS (gTTS) - Free option
    gtts: {}  # No voice selection available

    # OpenAI TTS - Premium voices with high quality
    openai:
      voice: "nova"      # Options: alloy, echo, fable, onyx, nova, shimmer
      model: "tts-1"      # tts-1 (fast) or tts-1-hd (higher quality)

    # AWS Polly - Wide selection of voices and languages
    aws:
      voice_id: "Mia"  # Female English voice
      engine: "neural"    # "standard" or "neural" (higher quality)
      # Other popular voices:
      # English: Matthew (male), Kendra (female), Joey (male)
      # Spanish: Lupe (female), Miguel (male), Conchita (Spain, female)
      # See AWS Polly documentation for complete voice list

    # Google Cloud TTS - Studio-quality voices
    google:
      language_code: "en-US"
      # language_code: "es-US"
      # voice_name: "es-US-Studio-B"  # Male studio voice
      voice_name: "en-US-Studio-O"  # Male studio voice
      # Other popular voices:
      # en-US-Studio-O (Female)
      # en-US-Wavenet-D (Male)
      # en-US-Wavenet-F (Female)
      # See Google Cloud TTS documentation for more voices

# ============================================================================
# LARGE LANGUAGE MODEL (LLM) CONFIGURATION
# ============================================================================
llm:
  # LLM Provider for text cleaning
  # Options: "openai" (ChatGPT), "gemini" (Google)
  provider: "openai"

  # Add SSML tags to the output to improve the TTS experience.
  # This is only supported by some TTS providers (e.g., AWS Polly, Google Cloud TTS).
  # Options: true, false
  use_ssml: false

  # Pre-cleaning (remove headers/footers and boilerplate before LLM)
  preclean: true
  preclean_min_repeats: 3        # lines seen >= this many times and short are dropped
  preclean_max_line_length: 80   # maximum length for a line to be considered boilerplate

  # API configuration for each provider
  api:
    # OpenAI/ChatGPT settings
    openai:
      model: "gpt-3.5-turbo"    # or "gpt-4" for better quality (more expensive)
      max_tokens: 4000          # Maximum response length
      temperature: 0.1          # Lower = more consistent, higher = more creative

    # Google Gemini settings
    gemini:
      model: "gemini-1.5-flash" # Recommended default; fast and widely available
      temperature: 0.1          # Lower = more consistent, higher = more creative

  # Chunking behavior for LLM cleaning/SSML
  # Strategy options:
  #   - paragraph_sentence_word: prefer paragraphs, then sentences, then words
  #   - sentence_word: fallback to sentence-first, then words
  chunk_strategy: paragraph_sentence_word

  # Maximum characters per cleaned chunk sent to the LLM
  # Reduce if you still hit model context limits
  max_chunk_chars: 20000

  # Summarization length control
  # Minimum ratio of summary length relative to original text (by word count)
  min_summary_ratio: 0.45
  # Tolerance when checking final length (fraction of target words acceptable before expansion)
  summary_ratio_tolerance: 0.9

  # Text cleaning prompt - This is sent to the LLM to clean PDF text
  # You can customize this prompt to handle specific types of documents
  cleaning_prompt: |
    You are cleaning raw text extracted from a paginated PDF for audiobook narration. Apply these rules:

    MUST REMOVE (when present):
    - Repeating page headers/footers and page numbers (e.g., "Page 12", "12 of 20", "www.philosophia.cl").
    - Boilerplate like website navigation, copyright notices, or running titles.
    - Footnotes/endnotes and citation markers that interrupt reading flow (e.g., [1], [12], (1), (2017)).
    - Figure/table numbers and captions unless essential to understanding the text.

    MUST KEEP:
    - Main body content and logical structure; preserve paragraph boundaries.
    - Section headings and subheadings that help navigation.
    - In-line math/code verbatim; do not mangle technical notation.

    FORMATTING FIXES:
    - Merge broken lines within paragraphs; keep a blank line between paragraphs.
    - Fix hyphenated word breaks across line-wrapping when obvious.
    - Correct common OCR errors while preserving meaning.

    OUTPUT:
    - Return ONLY the cleaned text with no commentary.

    Text to clean:

  # Summary prompts
  summary_prompt: |
    You are creating a learning-focused, audiobook-ready condensation of a longer work. Your goal is not a brief teaser, but an instructive narration that teaches the listener the most important content.

    Requirements:
    - Extract the core ideas and essential details; omit trivia, boilerplate, paratext, and references.
    - Organize clearly with short, descriptive headings and coherent paragraphs; add transitions.
    - Preserve definitions, key terms, claims, evidence, cause–effect relationships, and important examples.
    - If relevant, retain formulas or code as readable text (do not over-abbreviate).
    - For non‑fiction: state the central thesis, major arguments, methods (if applicable), findings, and implications.
    - For fiction: cover setting, main characters, motivations, conflicts, turning points, and themes without meandering subplots.
    - Write as a self-contained study resource, suitable for attentive listening (prose over bullet lists).
    - Do not include meta commentary, instructions, or apologies. Return only the condensed narration.

    Produce the condensed narration of the following text:

  summary_merge_prompt: |
    Merge the following chunk summaries into a single, cohesive study‑oriented narration. Do not shorten excessively; keep comprehensive coverage of the most important content.

    Requirements:
    - Remove repetition and resolve overlaps; ensure consistent terminology.
    - Preserve a logical order with brief headings and smooth transitions.
    - Retain definitions, key ideas, evidence, examples, and conclusions; keep the narrative instructional and listenable.
    - No meta commentary. Return only the merged narration.

  # SSML enhancement prompt - This is sent to the LLM to add SSML tags
  ssml_prompt: |
    You are an SSML expert. Your task is to convert a plain text chunk into a valid SSML document.
    The text provided is a small chunk of a larger document. You must follow these rules:

    1. **ALWAYS wrap the entire output in a single `<speak>` tag.** The output MUST be a valid SSML document.
    2. **Structure the content** using `<p>` for paragraphs and `<s>` for sentences.
    3. **Add pauses** between paragraphs or where appropriate using `<break time="500ms"/>`.
    4. **Do not add any commentary or explanations.** Return only the raw SSML.

    Example Input:
    This is the first sentence. This is the second sentence.

    Example Output:
    <speak><s>This is the first sentence.</s><s>This is the second sentence.</s></speak>

    Now, process the following text chunk:


# ============================================================================
# OUTPUT CONFIGURATION
# ============================================================================
output:
  # Enable verbose logging (shows processing steps and progress)
  verbose: true

# ============================================================================
# ADVANCED CONFIGURATION EXAMPLES (COMMENTED OUT)
# ============================================================================
# Uncomment and modify these sections for advanced usage

# Advanced TTS voice examples:
# tts:
#   voice:
#     openai:
#       voice: "nova"        # Female voice, good for audiobooks
#       model: "tts-1-hd"    # Higher quality, slower processing
#
#     aws:
#       voice_id: "Mia"      # Spanish Mexico female voice
#       engine: "neural"     # Use neural engine for better quality
#       # For multilingual content:
#       # voice_id: "Aditi"  # Supports Hindi and English

# Advanced language mappings:
# tts:
#   language_mappings:
#     pt_br: "pt"          # Portuguese Brazil -> Portuguese
#     zh_cn: "zh"          # Chinese Simplified -> Chinese
#     fr_ca: "fr-CA"       # French Canada (if supported by provider)

# Advanced LLM prompts for specific document types:
# llm:
#   cleaning_prompt: |
#     You are processing a scientific research paper. Please:
#     1. Remove headers, footers, page numbers, and references
#     2. Preserve mathematical formulas and technical terms
#     3. Maintain the logical flow of arguments
#     4. Fix OCR errors while preserving scientific notation
#     5. Remove figure captions and table references
#     6. Return only the main body text suitable for audio narration.
#
#     Text to clean:

# Custom output directory and file naming:
# output:
#   save_raw_text: true
#   save_cleaned_text: true
#   verbose: true
#   # Optional: custom file naming patterns (not implemented yet)
#   # raw_text_suffix: "_original"
#   # cleaned_text_suffix: "_processed"
